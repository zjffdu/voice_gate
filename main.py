import os
import pickle
import tempfile
import streamlit as st
import numpy as np
import soundfile as sf
from resemblyzer import VoiceEncoder, preprocess_wav
from scipy.spatial.distance import cdist
from datetime import datetime

DB_PATH = "voice_db.pkl"
AUDIO_DIR = "audio_samples"  # å­˜å‚¨å½•éŸ³æ–‡ä»¶çš„ç›®å½•

# ç¡®ä¿éŸ³é¢‘ç›®å½•å­˜åœ¨
os.makedirs(AUDIO_DIR, exist_ok=True)

# åˆå§‹åŒ–è¯­éŸ³ç¼–ç å™¨ï¼ˆä½¿ç”¨ç¼“å­˜é¿å…é‡å¤åŠ è½½ï¼‰
@st.cache_resource(show_spinner="æ­£åœ¨åŠ è½½è¯­éŸ³è¯†åˆ«æ¨¡å‹ï¼Œè¯·ç¨å€™...")
def get_encoder():
    return VoiceEncoder()

# é¢„åŠ è½½æ¨¡å‹ï¼ˆåº”ç”¨å¯åŠ¨æ—¶å°±åŠ è½½ï¼‰
with st.spinner("æ­£åœ¨åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å¼•æ“..."):
    encoder = get_encoder()

def embed_audio(audio_data, sr):
    """ä»éŸ³é¢‘æ•°æ®æå–ç‰¹å¾å‘é‡"""
    # å¦‚æœé‡‡æ ·ç‡ä¸æ˜¯16kHzï¼Œéœ€è¦é‡é‡‡æ ·ï¼ˆresemblyzeréœ€è¦16kHzï¼‰
    if sr != 16000:
        # ç®€å•é‡é‡‡æ ·ï¼ˆå®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦æ›´ä¸“ä¸šçš„é‡é‡‡æ ·ï¼‰
        audio_data = preprocess_wav(audio_data, source_sr=sr)
    else:
        audio_data = preprocess_wav(audio_data)
    return encoder.embed_utterance(audio_data).astype(np.float32)

def save_audio_sample(user_id, audio_data, sr, sample_index):
    """ä¿å­˜éŸ³é¢‘æ ·æœ¬åˆ°æ–‡ä»¶"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{user_id}_{sample_index}_{timestamp}.wav"
    filepath = os.path.join(AUDIO_DIR, filename)
    sf.write(filepath, audio_data, sr)
    return filepath

def load_db():
    """åŠ è½½ç”¨æˆ·æ•°æ®åº“"""
    if os.path.exists(DB_PATH):
        with open(DB_PATH, "rb") as f:
            db = pickle.load(f)
            # å…¼å®¹æ—§ç‰ˆæ•°æ®åº“ï¼ˆå¦‚æœæ˜¯æ—§æ ¼å¼ï¼Œè½¬æ¢ä¸ºæ–°æ ¼å¼ï¼‰
            if db and isinstance(list(db.values())[0], np.ndarray):
                # æ—§æ ¼å¼ï¼š{user_id: embedding}
                # è½¬æ¢ä¸ºæ–°æ ¼å¼ï¼š{user_id: {"embedding": embedding, "samples": []}}
                new_db = {}
                for user_id, embedding in db.items():
                    new_db[user_id] = {
                        "embedding": embedding,
                        "samples": [],
                        "created_at": datetime.now().isoformat()
                    }
                return new_db
            return db
    return {}

def save_db(db):
    """ä¿å­˜ç”¨æˆ·æ•°æ®åº“"""
    with open(DB_PATH, "wb") as f:
        pickle.dump(db, f)

st.title("ğŸ™ï¸ Voice Gate - å£°çº¹è¯†åˆ«ç³»ç»Ÿ")
st.markdown("---")

# åŠ è½½æ•°æ®åº“
db = load_db()

# åœ¨ä¾§è¾¹æ æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
with st.sidebar:
    st.header("ğŸ“Š ç³»ç»ŸçŠ¶æ€")
    st.metric("å·²æ³¨å†Œç”¨æˆ·", len(db))
    if db:
        total_samples = sum(len(user_data.get("samples", [])) if isinstance(user_data, dict) else 0 for user_data in db.values())
        st.metric("å½•éŸ³æ ·æœ¬æ€»æ•°", total_samples)
    st.markdown("---")
    st.info("ğŸ’¡ **ä½¿ç”¨æç¤º**\n\n1. é¦–æ¬¡ä½¿ç”¨è¯·å…ˆæ³¨å†Œç”¨æˆ·\n2. å½•éŸ³æ—¶ä¿æŒç¯å¢ƒå®‰é™\n3. æ¯æ¬¡å½•éŸ³å»ºè®®2-5ç§’\n4. éªŒè¯é˜ˆå€¼è¶Šé«˜è¶Šä¸¥æ ¼")

# ä½¿ç”¨tabsæ›¿ä»£radio
tab1, tab2, tab3 = st.tabs(["ğŸ‘¤ æ³¨å†Œç”¨æˆ·", "ğŸ” éªŒè¯èº«ä»½", "ğŸ“Š æ•°æ®åº“ç®¡ç†"])

with tab1:
    st.header("ğŸ‘¤ æ³¨å†Œæ–°ç”¨æˆ·")
    st.markdown("è¯·è¾“å…¥ç”¨æˆ·IDå¹¶å½•åˆ¶3æ®µè¯­éŸ³æ ·æœ¬æ¥å»ºç«‹å£°çº¹æ¡£æ¡ˆ")
    
    col1, col2 = st.columns([2, 1])
    with col1:
        user_id = st.text_input("ç”¨æˆ·ID", placeholder="ä¾‹å¦‚ï¼šå¼ ä¸‰ã€user001ç­‰")
    with col2:
        st.metric("éœ€è¦æ ·æœ¬æ•°", "3", help="ç³»ç»Ÿä¼šé€šè¿‡3æ®µè¯­éŸ³çš„å¹³å‡ç‰¹å¾å»ºç«‹æ›´å‡†ç¡®çš„å£°çº¹æ¨¡å‹")
    
    if user_id:
        st.success(f"âœ… ç”¨æˆ·ID: **{user_id}**")
        st.markdown("---")
        
        # åˆå§‹åŒ–session stateå­˜å‚¨å½•éŸ³
        if "enrollment_samples" not in st.session_state:
            st.session_state.enrollment_samples = []
        if "enrollment_audio_files" not in st.session_state:
            st.session_state.enrollment_audio_files = []
        
        # å½•åˆ¶3æ®µè¯­éŸ³
        progress_text = f"å½•éŸ³è¿›åº¦: {len(st.session_state.enrollment_samples)}/3"
        progress = len(st.session_state.enrollment_samples) / 3
        st.progress(progress, text=progress_text)
        st.markdown("")
        
        for i in range(3):
            with st.container(border=True):
                col_title, col_status = st.columns([3, 1])
                with col_title:
                    st.subheader(f"ğŸ¤ æ ·æœ¬ {i+1}")
                with col_status:
                    if len(st.session_state.enrollment_samples) > i:
                        st.success("âœ… å·²å®Œæˆ")
                    else:
                        st.warning("â³ å¾…å½•åˆ¶")
                
                audio_value = st.audio_input(f"ç‚¹å‡»å½•åˆ¶ç¬¬ {i+1} æ®µè¯­éŸ³", key=f"enroll_{i}")
                
                if audio_value:
                    # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                        tmp_file.write(audio_value.read())
                        tmp_path = tmp_file.name
                    
                    try:
                        # è¯»å–éŸ³é¢‘
                        audio_data, sr = sf.read(tmp_path)
                        
                        col_play, col_info = st.columns([2, 1])
                        with col_play:
                            st.audio(audio_value)
                        with col_info:
                            st.metric("æ—¶é•¿", f"{len(audio_data)/sr:.2f}ç§’")
                        
                        # æå–ç‰¹å¾
                        with st.spinner("ğŸ” æ­£åœ¨åˆ†æå£°çº¹ç‰¹å¾..."):
                            embedding = embed_audio(audio_data, sr)
                        
                        # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
                        saved_path = save_audio_sample(user_id, audio_data, sr, i+1)
                        
                        # å­˜å‚¨åˆ°session state
                        if len(st.session_state.enrollment_samples) <= i:
                            st.session_state.enrollment_samples.append(embedding)
                            st.session_state.enrollment_audio_files.append(saved_path)
                        else:
                            st.session_state.enrollment_samples[i] = embedding
                            st.session_state.enrollment_audio_files[i] = saved_path
                        
                        st.success("âœ¨ å£°çº¹ç‰¹å¾æå–å®Œæˆ")
                        os.unlink(tmp_path)
                    except Exception as e:
                        st.error(f"âŒ å¤„ç†éŸ³é¢‘æ—¶å‡ºé”™: {e}")
                        os.unlink(tmp_path)
        
        # æ³¨å†ŒæŒ‰é’®
        st.markdown("---")
        if len(st.session_state.enrollment_samples) == 3:
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                if st.button("âœ… å®Œæˆæ³¨å†Œ", type="primary", use_container_width=True):
                    with st.spinner("æ­£åœ¨ç”Ÿæˆå£°çº¹æ¨¡å‹..."):
                        # è®¡ç®—åŸå‹å‘é‡ï¼ˆ3ä¸ªæ ·æœ¬çš„å¹³å‡å€¼ï¼‰
                        prototype = np.mean(np.stack(st.session_state.enrollment_samples), axis=0)
                        db[user_id] = {
                            "embedding": prototype,
                            "samples": st.session_state.enrollment_audio_files.copy(),
                            "created_at": datetime.now().isoformat()
                        }
                        save_db(db)
                    st.balloons()
                    st.success(f"ğŸ‰ ç”¨æˆ· **{user_id}** æ³¨å†ŒæˆåŠŸï¼")
                    st.session_state.enrollment_samples = []
                    st.session_state.enrollment_audio_files = []
                    st.rerun()
        else:
            st.info(f"ğŸ“ è¯·å®Œæˆæ‰€æœ‰è¯­éŸ³æ ·æœ¬çš„å½•åˆ¶ (å½“å‰: {len(st.session_state.enrollment_samples)}/3)")

with tab2:
    st.header("ğŸ” éªŒè¯èº«ä»½")
    st.markdown("å½•åˆ¶ä¸€æ®µè¯­éŸ³ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨è¯†åˆ«æ‚¨çš„èº«ä»½")
    
    if not db:
        st.warning("âš ï¸ æ•°æ®åº“ä¸ºç©ºï¼Œè¯·å…ˆåœ¨ã€Œæ³¨å†Œç”¨æˆ·ã€é¡µé¢æ³¨å†Œ")
    else:
        col1, col2 = st.columns([3, 1])
        with col1:
            st.info(f"ğŸ’¾ æ•°æ®åº“ä¸­æœ‰ **{len(db)}** ä½å·²æ³¨å†Œç”¨æˆ·")
        with col2:
            threshold = st.slider("é˜ˆå€¼", 0.0, 1.0, 0.75, 0.05, help="ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œè¶Šé«˜è¶Šä¸¥æ ¼")
        
        st.markdown("---")
        audio_value = st.audio_input("ğŸ¤ ç‚¹å‡»å½•åˆ¶éªŒè¯è¯­éŸ³")
        
        if audio_value:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                tmp_file.write(audio_value.read())
                tmp_path = tmp_file.name
            
            try:
                # è¯»å–éŸ³é¢‘
                audio_data, sr = sf.read(tmp_path)
                
                col_play, col_info = st.columns([2, 1])
                with col_play:
                    st.audio(audio_value)
                with col_info:
                    st.metric("æ—¶é•¿", f"{len(audio_data)/sr:.2f}ç§’")
                
                # æå–ç‰¹å¾å¹¶éªŒè¯
                with st.spinner("ğŸ” æ­£åœ¨åˆ†æå£°çº¹ç‰¹å¾å¹¶éªŒè¯èº«ä»½..."):
                    probe = embed_audio(audio_data, sr).reshape(1, -1)
                    
                    # ä¸æ•°æ®åº“ä¸­æ‰€æœ‰ç”¨æˆ·æ¯”è¾ƒ
                    keys = list(db.keys())
                    mats = np.stack([db[k]["embedding"] if isinstance(db[k], dict) else db[k] for k in keys], axis=0)
                    sims = 1 - cdist(probe, mats, metric="cosine")[0]
                
                # æ‰¾åˆ°æœ€åŒ¹é…çš„ç”¨æˆ·
                best_i = np.argmax(sims)
                matched_user = keys[best_i]
                similarity = sims[best_i]
                
                st.markdown("---")
                st.subheader("ğŸ¯ éªŒè¯ç»“æœ")
                
                # ä½¿ç”¨å¤§å·æ˜¾ç¤ºç»“æœ
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("æœ€åŒ¹é…ç”¨æˆ·", matched_user)
                with col2:
                    st.metric("ç›¸ä¼¼åº¦", f"{similarity:.1%}", delta=f"é˜ˆå€¼ {threshold:.1%}")
                
                if similarity >= threshold:
                    st.success(f"âœ… **éªŒè¯é€šè¿‡ï¼** æ¬¢è¿å›æ¥ï¼Œ{matched_user} ğŸ‘‹")
                else:
                    st.error(f"âŒ **éªŒè¯å¤±è´¥ï¼** ç›¸ä¼¼åº¦ ({similarity:.1%}) ä½äºé˜ˆå€¼ ({threshold:.1%})")
                
                # æ˜¾ç¤ºæ‰€æœ‰ç”¨æˆ·çš„ç›¸ä¼¼åº¦
                with st.expander("ğŸ“Š æŸ¥çœ‹è¯¦ç»†åŒ¹é…ç»“æœ", expanded=False):
                    st.markdown("**æ‰€æœ‰ç”¨æˆ·ç›¸ä¼¼åº¦æ’åï¼š**")
                    # æ’åºæ˜¾ç¤º
                    sorted_indices = np.argsort(sims)[::-1]
                    for rank, idx in enumerate(sorted_indices, 1):
                        user = keys[idx]
                        sim = sims[idx]
                        emoji = "ğŸ¥‡" if rank == 1 else "ğŸ¥ˆ" if rank == 2 else "ğŸ¥‰" if rank == 3 else "ã€€"
                        color = "ğŸŸ¢" if sim >= threshold else "ğŸ”´"
                        st.write(f"{emoji} **{rank}.** {user}: {color} {sim:.1%}")
                        st.progress(sim)
                
                os.unlink(tmp_path)
            except Exception as e:
                st.error(f"å¤„ç†éŸ³é¢‘æ—¶å‡ºé”™: {e}")
                os.unlink(tmp_path)

with tab3:
    st.header("ğŸ“Š æ•°æ®åº“ç®¡ç†")
    st.markdown("æŸ¥çœ‹ã€ç®¡ç†å·²æ³¨å†Œç”¨æˆ·çš„å£°çº¹æ•°æ®")
    
    if not db:
        st.info("ğŸ“­ æ•°æ®åº“ä¸ºç©ºï¼Œè¯·å…ˆåœ¨ã€Œæ³¨å†Œç”¨æˆ·ã€é¡µé¢æ³¨å†Œ")
    else:
        # ç»Ÿè®¡ä¿¡æ¯
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ğŸ‘¥ ç”¨æˆ·æ€»æ•°", len(db))
        with col2:
            total_samples = sum(len(user_data.get("samples", [])) if isinstance(user_data, dict) else 0 for user_data in db.values())
            st.metric("ğŸµ æ ·æœ¬æ€»æ•°", total_samples)
        with col3:
            avg_samples = total_samples / len(db) if len(db) > 0 else 0
            st.metric("ğŸ“ˆ å¹³å‡æ ·æœ¬", f"{avg_samples:.1f}")
        
        st.markdown("---")
        
        # éå†æ¯ä¸ªç”¨æˆ·
        for idx, user_id in enumerate(list(db.keys()), 1):
            user_data = db[user_id]
            
            # ä½¿ç”¨expanderæ˜¾ç¤ºç”¨æˆ·è¯¦æƒ…
            with st.expander(f"ğŸ‘¤ **{idx}. {user_id}**", expanded=False):
                # ç”¨æˆ·ä¿¡æ¯å¡ç‰‡
                info_col, action_col = st.columns([3, 1])
                
                with info_col:
                    # æ˜¾ç¤ºç”¨æˆ·åŸºæœ¬ä¿¡æ¯
                    if isinstance(user_data, dict):
                        created_time = user_data.get('created_at', 'æœªçŸ¥')
                        if created_time != 'æœªçŸ¥':
                            try:
                                from datetime import datetime
                                dt = datetime.fromisoformat(created_time)
                                created_time = dt.strftime("%Y-%m-%d %H:%M")
                            except:
                                pass
                        
                        col_a, col_b = st.columns(2)
                        with col_a:
                            st.markdown(f"ğŸ“… **æ³¨å†Œæ—¶é—´**: {created_time}")
                        with col_b:
                            st.markdown(f"ğŸµ **æ ·æœ¬æ•°é‡**: {len(user_data.get('samples', []))} ä¸ª")
                    else:
                        st.info("â„¹ï¸ æ—§ç‰ˆæœ¬æ•°æ®ï¼ˆä»…åŒ…å«å£°çº¹ç‰¹å¾ï¼‰")
                
                with action_col:
                    # åˆ é™¤ç”¨æˆ·æŒ‰é’®
                    if st.button("ğŸ—‘ï¸ åˆ é™¤", key=f"del_{user_id}", type="secondary", use_container_width=True):
                        # åˆ é™¤éŸ³é¢‘æ–‡ä»¶
                        if isinstance(user_data, dict) and "samples" in user_data:
                            for audio_path in user_data["samples"]:
                                if os.path.exists(audio_path):
                                    os.remove(audio_path)
                        
                        # åˆ é™¤æ•°æ®åº“è®°å½•
                        del db[user_id]
                        save_db(db)
                        st.success(f"âœ… å·²åˆ é™¤ç”¨æˆ· {user_id}")
                        st.rerun()
                
                st.markdown("---")
                
                # æ˜¾ç¤ºå½•éŸ³æ ·æœ¬
                if isinstance(user_data, dict) and "samples" in user_data:
                    if user_data["samples"]:
                        st.markdown("##### ğŸµ å½•éŸ³æ ·æœ¬")
                        
                        for idx, audio_path in enumerate(user_data["samples"], 1):
                            with st.container(border=True):
                                if os.path.exists(audio_path):
                                    col_audio, col_delete = st.columns([5, 1])
                                    
                                    with col_audio:
                                        st.markdown(f"**æ ·æœ¬ {idx}** Â· `{os.path.basename(audio_path)}`")
                                        st.audio(audio_path)
                                    
                                    with col_delete:
                                        if st.button("ğŸ—‘ï¸", key=f"del_audio_{user_id}_{idx}", help="åˆ é™¤æ­¤æ ·æœ¬"):
                                            # åˆ é™¤éŸ³é¢‘æ–‡ä»¶
                                            os.remove(audio_path)
                                            
                                            # ä»æ•°æ®åº“ä¸­ç§»é™¤
                                            user_data["samples"].remove(audio_path)
                                            save_db(db)
                                            
                                            st.success(f"âœ… å·²åˆ é™¤æ ·æœ¬ {idx}")
                                            st.rerun()
                                else:
                                    st.warning(f"âš ï¸ æ ·æœ¬ {idx}: æ–‡ä»¶ä¸å­˜åœ¨")
                                    st.caption(f"è·¯å¾„: {audio_path}")
                        
                        st.markdown("---")
                    else:
                        st.info("â„¹ï¸ è¯¥ç”¨æˆ·æš‚æ— å½•éŸ³æ ·æœ¬")
                    
                    # æ·»åŠ æ–°å½•éŸ³æ ·æœ¬ï¼ˆæ— è®ºæ˜¯å¦æœ‰æ ·æœ¬éƒ½æ˜¾ç¤ºï¼‰
                    st.markdown("##### â• æ·»åŠ æ–°æ ·æœ¬")
                    new_audio = st.audio_input(f"ä¸ºç”¨æˆ· {user_id} å½•åˆ¶æ–°æ ·æœ¬", key=f"add_audio_{user_id}")
                    
                    # ä½¿ç”¨session stateè·Ÿè¸ªå·²å¤„ç†çš„éŸ³é¢‘ï¼Œé¿å…é‡å¤æ·»åŠ 
                    audio_session_key = f"processed_audio_{user_id}"
                    if audio_session_key not in st.session_state:
                        st.session_state[audio_session_key] = None
                    
                    if new_audio:
                        # è·å–éŸ³é¢‘çš„å”¯ä¸€æ ‡è¯†ï¼ˆä½¿ç”¨éŸ³é¢‘æ•°æ®çš„å“ˆå¸Œå€¼ï¼‰
                        audio_bytes = new_audio.getvalue()
                        import hashlib
                        audio_hash = hashlib.md5(audio_bytes).hexdigest()
                        
                        # åªæœ‰å½“è¿™æ˜¯æ–°çš„éŸ³é¢‘æ—¶æ‰å¤„ç†
                        if st.session_state[audio_session_key] != audio_hash:
                            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                                tmp_file.write(audio_bytes)
                                tmp_path = tmp_file.name
                            
                            try:
                                with st.spinner("æ­£åœ¨å¤„ç†æ–°æ ·æœ¬å¹¶æ›´æ–°å£°çº¹ç‰¹å¾..."):
                                    # è¯»å–éŸ³é¢‘
                                    audio_data, sr = sf.read(tmp_path)
                                    
                                    # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
                                    next_index = len(user_data["samples"]) + 1
                                    saved_path = save_audio_sample(user_id, audio_data, sr, next_index)
                                    
                                    # æå–ç‰¹å¾å¹¶æ›´æ–°åŸå‹å‘é‡
                                    new_embedding = embed_audio(audio_data, sr)
                                    
                                    # é‡æ–°è®¡ç®—åŸå‹å‘é‡ï¼ˆæ‰€æœ‰æ ·æœ¬çš„å¹³å‡å€¼ï¼‰
                                    all_embeddings = [new_embedding]
                                    for sample_path in user_data["samples"]:
                                        if os.path.exists(sample_path):
                                            sample_audio, sample_sr = sf.read(sample_path)
                                            all_embeddings.append(embed_audio(sample_audio, sample_sr))
                                    
                                    user_data["embedding"] = np.mean(np.stack(all_embeddings), axis=0)
                                    user_data["samples"].append(saved_path)
                                    save_db(db)
                                    
                                    # æ ‡è®°è¿™ä¸ªéŸ³é¢‘å·²å¤„ç†
                                    st.session_state[audio_session_key] = audio_hash
                                
                                os.unlink(tmp_path)
                                st.success(f"âœ… æ–°æ ·æœ¬å·²æ·»åŠ ï¼Œå£°çº¹ç‰¹å¾å·²æ›´æ–°")
                                st.rerun()
                            except Exception as e:
                                st.error(f"âŒ å¤„ç†éŸ³é¢‘æ—¶å‡ºé”™: {e}")
                                if os.path.exists(tmp_path):
                                    os.unlink(tmp_path)
                        else:
                            # éŸ³é¢‘å·²å¤„ç†è¿‡ï¼Œæ˜¾ç¤ºæç¤º
                            st.info("â„¹ï¸ æ­¤éŸ³é¢‘æ ·æœ¬å·²æ·»åŠ ï¼Œè¯·å½•åˆ¶æ–°çš„éŸ³é¢‘")
                else:
                    st.info("â„¹ï¸ è¯¥ç”¨æˆ·æ•°æ®æ ¼å¼å¼‚å¸¸ï¼ˆå¯èƒ½æ˜¯æ—§ç‰ˆæœ¬æ•°æ®ï¼‰")

